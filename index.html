<!doctype html>
<!-- The Time Machine GitHub pages theme was designed and developed by Jon Rohan, on Feb 7, 2012. -->
<!-- Follow him for fun. http://twitter.com/jonrohan. Tail his code on https://github.com/jonrohan -->
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <link rel="stylesheet" href="stylesheets/stylesheet.css" media="screen">
  <link rel="stylesheet" href="stylesheets/github-dark.css">
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
  <script type="text/javascript" src="javascripts/script.js"></script>

  <title>Pmlproject</title>
  <meta name="description" content="">

  <meta name="viewport" content="width=device-width,initial-scale=1">

</head>

<body>

  <div class="wrapper">
    <header>
      <h1 class="title">Pmlproject</h1>
    </header>
    <div id="container">
      <p class="tagline"></p>
      <div id="main" role="main">
        <div class="download-bar">
        <div class="inner">
          <a href="https://github.com/primavista40/PMLproject/tarball/master" class="download-button tar"><span>Download</span></a>
          <a href="https://github.com/primavista40/PMLproject/zipball/master" class="download-button zip"><span>Download</span></a>
          <a href="https://github.com/primavista40/PMLproject" class="code">View Pmlproject on GitHub</a>
        </div>
        <span class="blc"></span><span class="trc"></span>
        </div>
        <article class="markdown-body">
          <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>

<p></p>ML Project



<p>

</p>



code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}


<div>


<div id="header">
<h1>
<a id="ml-project" class="anchor" href="#ml-project" aria-hidden="true"><span class="octicon octicon-link"></span></a>ML Project</h1>
<h4>
<a id="pite" class="anchor" href="#pite" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Pite</em>
</h4>
<h4>
<a id="monday-may-18-2015" class="anchor" href="#monday-may-18-2015" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Monday, May 18, 2015</em>
</h4>
</div>

<p>In this particular project, we shall be looking to apply Machine Learning algorithm to classify several types of physical activities using the data about the movement of users’ body. We first load necessary packages</p>

<pre><code>library(caret)</code></pre>

<pre><code>## Warning: package 'caret' was built under R version 3.1.3</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>

<pre><code>library(randomForest)</code></pre>

<pre><code>## Warning: package 'randomForest' was built under R version 3.1.3</code></pre>

<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>

<p>Then, we read the data</p>

<pre><code>train&lt;-read.csv("pml-training.csv")
final&lt;-read.csv("pml-testing.csv")</code></pre>

<p>Note that I am calling the last 20 test cases as the ‘final’ training set as I will split the data in the training set for cross-validations.By looking at the data, we can see that the variables with the name begining with ‘kurtosis’, ‘skewness’ etc. have a lot of missing values(only around 1/20 is recorded+all missing in the final set). So, we can take those variables out of our model.</p>

<pre><code>factors&lt;-colnames(train)
smallTrain&lt;-train[,-c(grep('kurtosis',factors),grep('skewness',factors),grep('avg',factors),grep('var',factors)
          ,grep('stddev',factors),grep('min',factors),grep('max',factors),grep('amplitude',factors))]
smallFinal&lt;-final[,-c(grep('kurtosis',factors),grep('skewness',factors),grep('avg',factors),grep('var',factors)
                    ,grep('stddev',factors),grep('min',factors),grep('max',factors),grep('amplitude',factors))]
#also first 7 columns are irrelevant
used&lt;-smallTrain[,8:60]
finalUsed&lt;-smallFinal[,8:60]</code></pre>

<p>Now that we have tidied our data, we will be looking to train our model. As we still have 53 variables left, it is still questionable if our model will lead to overfitting. Hence, we split our data into 70% training and 30% testing.</p>

<pre><code>inTrain&lt;-createDataPartition(used$classe,p=0.7,list=FALSE)
trainUsed&lt;-used[inTrain,]
testUsed&lt;-used[-inTrain,]</code></pre>

<p>Since this is a classification problem, the most natural way of training this would be via decision trees. However, building just one tree seems to have quite a lot of variation to how variables are selected. We instead use the Random Forest method which takes the votes from 500 trees and decide the outcomes.</p>

<pre><code>modFit&lt;-randomForest(classe~.,data=trainUsed)
modFit</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = classe ~ ., data = trainUsed) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.54%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 3903    3    0    0    0 0.0007680492
## B   14 2640    4    0    0 0.0067720090
## C    0   15 2379    2    0 0.0070951586
## D    0    0   26 2224    2 0.0124333925
## E    0    0    3    5 2517 0.0031683168</code></pre>

<p>This have quite a small in sample rate(missing only 73 out of 13737 observations). However, this could be resulted from overfitting. Hence, we verify it on the ‘train’ set that we split earlier. We can then construct our confusion matrix. This is still a very good fit(missing ~35 out of 5885). So, we can expect the out of sample error to be very small(&lt;1%).</p>

<pre><code>predicted&lt;-predict(modFit,testUsed)
table(predicted,testUsed$classe)</code></pre>

<pre><code>##          
## predicted    A    B    C    D    E
##         A 1672    3    0    0    0
##         B    2 1132    7    0    0
##         C    0    4 1019   10    1
##         D    0    0    0  954    2
##         E    0    0    0    0 1079</code></pre>

<p>We can then build the final prediction on our ‘final’ test set</p>

<pre><code>answers&lt;-as.character(predict(modFit,finalUsed))</code></pre>

<p>In conclusion, although this Machine Learning algorithm gives very accurate prediction, it could take a really long time to run. We might be able to reduce the complexity of our computation for further scaling. We can look at the Gini importance factor to see which factor is the most influential and leace those that is not as important.</p>

<pre><code>importance(modFit)</code></pre>

<pre><code>##                      MeanDecreaseGini
## roll_belt                   880.37479
## pitch_belt                  484.88215
## yaw_belt                    604.49142
## total_accel_belt            159.71593
## gyros_belt_x                 64.91080
## gyros_belt_y                 78.43052
## gyros_belt_z                218.99166
## accel_belt_x                 81.06290
## accel_belt_y                 90.27144
## accel_belt_z                275.01726
## magnet_belt_x               177.03496
## magnet_belt_y               266.70110
## magnet_belt_z               274.61923
## roll_arm                    232.71762
## pitch_arm                   111.34188
## yaw_arm                     177.60961
## total_accel_arm              74.78201
## gyros_arm_x                  95.06065
## gyros_arm_y                  98.03659
## gyros_arm_z                  43.23709
## accel_arm_x                 162.83763
## accel_arm_y                 103.56164
## accel_arm_z                  92.76430
## magnet_arm_x                180.16246
## magnet_arm_y                165.87862
## magnet_arm_z                131.83883
## roll_dumbbell               294.50252
## pitch_dumbbell              129.68295
## yaw_dumbbell                180.04039
## total_accel_dumbbell        199.37789
## gyros_dumbbell_x             92.08904
## gyros_dumbbell_y            181.78357
## gyros_dumbbell_z             62.24341
## accel_dumbbell_x            167.54297
## accel_dumbbell_y            293.98423
## accel_dumbbell_z            236.34501
## magnet_dumbbell_x           326.31522
## magnet_dumbbell_y           475.20248
## magnet_dumbbell_z           527.56092
## roll_forearm                414.35606
## pitch_forearm               559.11542
## yaw_forearm                 121.97627
## total_accel_forearm          77.30833
## gyros_forearm_x              56.48817
## gyros_forearm_y              88.69932
## gyros_forearm_z              59.35902
## accel_forearm_x             219.59574
## accel_forearm_y              98.73804
## accel_forearm_z             168.74359
## magnet_forearm_x            155.28918
## magnet_forearm_y            145.62481
## magnet_forearm_z            201.74875</code></pre>

<p></p>
</div>







<p>
</p>
        </article>
      </div>
    </div>
    <footer>
      <div class="owner">
      <p><a href="https://github.com/primavista40" class="avatar"><img src="https://avatars2.githubusercontent.com/u/9353529?v=3&amp;s=60" width="48" height="48"></a> <a href="https://github.com/primavista40">primavista40</a> maintains <a href="https://github.com/primavista40/PMLproject">Pmlproject</a></p>


      </div>
      <div class="creds">
        <small>This page generated using <a href="https://pages.github.com/">GitHub Pages</a><br>theme by <a href="https://twitter.com/jonrohan/">Jon Rohan</a></small>
      </div>
    </footer>
  </div>
  <div class="current-section">
    <a href="#top">Scroll to top</a>
    <a href="https://github.com/primavista40/PMLproject/tarball/master" class="tar">tar</a><a href="https://github.com/primavista40/PMLproject/zipball/master" class="zip">zip</a><a href="" class="code">source code</a>
    <p class="name"></p>
  </div>

  
</body>
</html>
